# Captainâ€™s Log Index

Navigate the cosmic mess of development!  
## ğŸš€ Project Highlights

- [Space Junk #004](#space-junk-004) â€” First Agent Training Milestone  
- [Space Junk #012](#space-junk-012) â€” The Great Reward Revelation  
- [Space Junk #014](#space-junk-014) â€” New Frontier: Agent-vs-Agent & Evolution

---

## Space Junk Template

**Mission Time:** {date / timestamp}  
**Coordinates:** {stage of project / milestone}

#### ğŸš€ Context:
Summary of what you tried or built. Code, features, experiments, bugs, new approachesâ€¦ whatever you were working on. Be concise or detailedâ€”your call!

#### ğŸŒŒ Thoughts:
What did you learn, realize, or face? Unexpected bugs, breakthrough ideas, obstacles, or even emotional highs/lowsâ€”share it all!

#### ğŸ› ï¸ Insights:
Key code changes, experiments run, or configuration tweaks. Screenshots or code snippets welcome.

#### ğŸ§­ Next:
Whatâ€™s next? Next action, open questions, or reflections about where youâ€™ll go from here.

#### ğŸ«  Mood:
Share a meme-able moment or a one-liner about how you feel.



# Space Junk #001

**Coordinates:** Phase 1 â€“ Project Foundation

#### ğŸš€ Context:
Launched the mission! Established the overall vision: to build a modular, gym-compatible RL environment inspired by classic spaceship duels. Started the project repo and directory layout. Core files for `constants.py`, `actions.py`, and `spaceship.py` created.


#### ğŸ› ï¸ Insights:
- Defined constants for colors, screen, ship, etc.
- Laid out clear, modular folder structure (`core/`, `envs/`, `scripts/`).
- Committed to phase-based milestones for growth.

#### ğŸ§­ Next:
Get *something* visible! Implement a basic `Spaceship` class and show the first pixel movement. Proof-of-life required.

# Space Junk #002

**Coordinates:** Phase 1 â€“ Visual Feedback

#### ğŸš€ Context:
Spaceships appeared on the screen for the first time! Manual controls (WASD) enabled for a human pilot. Wrote `human_play.py` script for interactive testing.

#### ğŸ› ï¸ Insights:
- Implemented the spaceship `draw()` and `move()` logic.
- Added user input loop for manual play.
- Project structure now supports flexible run scripts.

#### ğŸ§­ Next:
Add interaction! Design bullet mechanics, enable firing, and build a collision system. RL without feedback is like a ship with no thrusters.

# Space Junk #003

**Coordinates:** Phase 2 â€“ Bullets & Combat

#### ğŸš€ Context:
First taste of combat. Bullets, shooting delays, health points, and basic collision detection landed. Now the void shoots back!

#### ğŸ› ï¸ Insights:
- Created `bullet.py` and bullet logic in ships.
- Implemented health tracking and rewards.
- Added per-frame update system for movement and collision.

#### ğŸ§­ Next:
Begin simple agent logic and baseline AI. Make it possible for â€œthe voidâ€ to fight back!

# Space Junk #004
**Mission Time:** 2025-06-19 11:15am  
**Coordinates:** Phase 3 â€“ Agent Training

#### ğŸš€ Context:
Integrated PPO agent from Stable Baselines3. Model checkpointing and experiment tracking now online! Watched as the AI began to *almost* learn basic survival and combat. Human-level not yet, but stars are aligning.

Created logs module to the repo, to keep track of all the madness.

#### ğŸŒŒ Thoughts:
Thereâ€™s so much I want to share, but what excites me the most is knowing these stories will live on through my work.  
About the agent: it moves! ğŸ˜‚ It doesnâ€™t really have a sense of purpose yet, but when it manages to survive those first few seconds, it almost feels alive.


#### ğŸ› ï¸ Insights:
- Added experiment log and checkpointing callbacks.
- Fixed obs shape mismatches and bugs.
- Evaluated model: agent dodges and shoots (sometimes!).

#### ğŸ§­ Next:
Refine reward logic, implement more advanced agent logic, and document all the moving parts for future explorers.

#### ğŸ¥²âœ¨ Mood:
So happy to se my hours of work kinda alife!

# Space Junk #005

**Mission Time:** 2025-06-19 10:28pm  
**Coordinates:** Phase 3 - Agent Training (logging)

#### ğŸš€ Context:
Attempted to roll out the shiny new logging utilities from the utils directory, eager to track my agentâ€™s performance in experiment_results.csv. 


#### ğŸŒŒ Thoughts:
Thereâ€™s something oddly satisfying about watching numbers appear in the log fileâ€¦ if only they actually did. Spent a good chunk of time marveling at my agentâ€™s questionable life choices, and wondering, "Will this training ever end?" (Spoiler: Not today.)

#### ğŸ› ï¸ Insights:
The agent gamely pressed on until the final reward, but it turns out all that time was for naughtâ€”my logging function had a bug and none of the results made it to the CSV.

#### ğŸ§­ Next:
Fix the logging error and give it another go.

#### ğŸ˜‘ Mood:
Are you kidding me?.

# Space Junk #006

**Mission Time:** 2025-06-20 12:20am  
**Coordinates:** Phase 3 - Agent Training (logging II)

#### ğŸš€ Context:
Running the experiment again, this time with the logging function fixed.

#### ğŸŒŒ Thoughts:
The reward system is inefficient in this environment.
Itâ€™s curious how the agent tends to move downward often.
The notes parameter in the logger feels useless right nowâ€”maybe it would help if I left meaningful comments for reviewers, but for now I realize: I canâ€™t comment on events I havenâ€™t logged.

#### ğŸ› ï¸ Insights:
It would be useful to track episode duration.
I want to link the CSV log info with the agentâ€™s parameters and environment settings.

#### ğŸ§­ Next:
How do I turn this agent into a gladiator who relentlessly seeks victory?

#### ğŸ«  Mood:
Smooth runs always leave room to breatheâ€”sometimes itâ€™s just hot air in endless training.

# Space Junk #007

**Mission Time:** 2025-06-23 12:22pm  
**Coordinates:** Phase 3 - Agent Training (Truncated)

#### ğŸš€ Context:
I needed to handle evaluations to make it bearable and avoid infinite dummy loops.

#### ğŸŒŒ Thoughts:
Why did the answer hide in plain sight, cloaked in the quiet folds of â€œtruncatedâ€?
Sometimes the mind must pause, rest, and let the stars align before truth can shine.

#### ğŸ› ï¸ Insights:
I gained a better understanding of the Gymnasium API.
Resting clears the fog, revealing what was always there, just beyond tired eyes.

#### ğŸ§­ Next:
Train a invinsible agent

#### ğŸ«  Mood:
Time slips through my fingers like cosmic dustâ€”
I must finish this now, or be forever lost in the endless spiral of beginnings.

# Space Junk #008

**Mission Time:** 2025-06-23 06:00pm  
**Coordinates:** Phase 3 - Agent Training (Rendering)

#### ğŸš€ Context:  
After enhancing the red ship's behavior, I wanted to evaluate it.  
For that reason, I added a new file to handle rendering without modifying the original human_play.py file.

#### ğŸŒŒ Thoughts:  
The gameplay is very hard for a human; the movement has many bugs and the movement limitations are not well set,  
however, this can be a good feature for training an agent.

#### ğŸ› ï¸ Insights:  
Need a refactor of the envs to make it more modular and easier to test.

#### ğŸ§­ Next:  
Evaluate agent with new red ship behavior.

#### ğŸ«  Mood:  
Cleaning is a chore no one wants to do, but it is necessary to keep the ship afloat.

# Space Junk #009

**Mission Time:** 2025-06-23 06:41pm  
**Coordinates:** Phase 3 - Agent Training (Enemy AI)

#### ğŸš€ Context:  
Refactored the envs to make them more modular and easier to test.  
Trained a model with 500k steps that performed better than the previous one.  
- This agent has only 2 lives, which are more valuable than the previous 4 lives.  
- The red ship follows the yellow ship along the Y axis and tries to maintain distance on the X axis.  
- Both ships fire randomly.

#### ğŸŒŒ Thoughts:  
You donâ€™t know what you have until you lose it! After being nerfed from 4 to 2 lives, the yellow ship shows more survival and attacking behavior.  
The better the environment, the better the training.

#### ğŸ› ï¸ Insights:  
The ships behave better; however, the agent is still not able to learn the best strategy to win.

#### ğŸ§­ Next:  
- Make the last trained agent the enemy.  

#### ğŸ«  Mood:  
My back hurts! I'm at school and trying to work on this project.

# Space Junk #010

**Mission Time:** 2025-06-24 03:44 PM  
**Coordinates:** Phase 3 - Agent Training ('V' models)

#### ğŸš€ Context:  
After training several models, I tried a different approach and now Iâ€™m naming the models 'V#' (# is the model number).

I found it interesting that the environment leads to very short combats; itâ€™s too easy to lose or win since the only thing needed is to shoot and hit the enemy.

In some models, I managed to make them dodge but they wouldnâ€™t fire, so they were survivors, not warriors.

In other models, I made them fire but not dodge, so they were kamikazes, not winners.

#### ğŸŒŒ Thoughts:  
- Changing the environment (e.g., starting positions of the ships so they donâ€™t face each other from the beginning) will improve exploration.

#### ğŸ› ï¸ Insights:  
The current model, V3, only dodges when bullets are fired but does not aim to hit the enemy.

#### ğŸ§­ Next Steps:  
- Modify the environment to encourage better exploration.

#### ğŸ§ª Mood:  
I feel just like a true scientist. 

# Space Junk #011

**Mission Time:** 2025-06-25 01:59 AM  
**Coordinates:** Phase 3 - Agent Training ('V' BUGS)

#### ğŸš€ Context:  
After training several models, I noticed all of them only move up or down with no other apparent behavior during evaluation runs. This indicates there is a bug that I need to find.

#### ğŸŒŒ Thoughts:  
- At some point, I must have changed something that broke the agents' training.
- However, model V5 performs pretty well compared to others, so I will check what conditions V5 was trained under to find the bug.

#### ğŸ› ï¸ Insights:  
Models trained after V5 could have worked properly if the bug didnâ€™t exist!

#### ğŸ§­ Next Steps:  
- Fix the bug.

#### ğŸ¤¯ Mood:  
A lot of work and thinking for this, really? 

# Space Junk #012

**Mission Time:** 2025-06-25 01:13 AM  
**Coordinates:** Phase 3 - Agent Training (REWARDS)

#### ğŸš€ Context:  
- Iâ€™ve been digging through past project versions, hunting for the source of this issueâ€”and itâ€™s exhausting!
- Iâ€™ve trained more â€œinsightfulâ€ agents, but the red ship (the enemy in the environment) is still allowing lazy behaviors.

#### ğŸŒŒ Thoughts:  
- The best way to fix bugs is to prevent them in the first place.
- I need to document things better to keep track of the projectâ€™s evolution and avoid these energy-draining, soul-sapping debugging sessions.
- A better environment will breed better models.

#### ğŸ› ï¸ Insights:  
The problem wasnâ€™t in the code logic, but in the **reward system**.

#### ğŸ§­ Next Steps:  
- Upgrade, modify, or do whateverâ€™s necessary to improve training.
- Maybe itâ€™s time for a better red ship AI?!

#### ğŸ§  Mood:  
Reading the same code over and over is a good cardio workout for the mind, XD.  
Honestly, itâ€™s like running a marathon, a mental fight above all else!

# Space Junk #013

**Mission Time:** 2025-06-26 10:12 AM  
**Coordinates:** Phase 3 - Agent Training ('B' models)

#### ğŸš€ Context:  
- Tweaked the rewards only slightly and trained multiple models with ~3k timesteps each to observe performance changes. 

#### ğŸŒŒ Thoughts:  
- The agent, when trained against the baseline enemy, achieves its goal quite wellâ€”given enough timesteps and a logical reward system. 
- For multiplayer combat, what we need are *skills*, not just systems. 

#### ğŸ› ï¸ Insights:  
- Each model achieves different performance, but all seem to follow the reward system as faithfully as devotees follow their gods. 

#### ğŸ§­ Next Steps:  
- Build an environment where models can train against other training models, so both can evolve with each iteration. 

#### â˜•ğŸš¶â€â™‚ï¸âœ¨ Mood:  
- Sleepy, but the road Iâ€™ve traveled keeps me going. 

# Space Junk #014

**Mission Time:** 2025-06-26 01:42 AM  
**Coordinates:** Phase 3 - Agent Training ('X' models)

#### ğŸš€ Context:  
- New environment for training agent vs agent.
- New training script.
- New trained model.

#### ğŸŒŒ Thoughts:  
- I was hoping for better results, but I realized the process I had in mind requires a different approach.

#### ğŸ› ï¸ Insights:  
- With this new environment, I can only train one learning agent versus a random agentâ€”not true dual-agent learning yet.

#### ğŸ§­ Next Steps:  
- Close the project with a README.md and continue on my quest to master both NEAT and RL worlds.

#### ğŸ¥±ğŸ™âœ¨ Mood:  
- Still sleepy, but grateful for the chance to learn by doing!

